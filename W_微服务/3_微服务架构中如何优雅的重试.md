[微服务架构中如何优雅的重试？](https://blog.51cto.com/u_7117633/2864527)

1. 背景
   1. 在微服务架构中，一个系统被拆分成多个小服务，小服务之间大量RPC调用，经常可能因为“网络抖动等原因”造成RPC调用失败，这时使用“重试机制”可以提高请求的最终成功率，减少故障影响，让系统运行更稳定
   2. 重试的优点：提高服务的稳定性
2. 重试的风险
   - 虽然重试能提高服务的稳定性，但是一般情况下大家都不会轻易去重试，或者说不敢重试，主要是因为重试有“放大故障的风险”
      1. 重试会加大直接下游的负载
      2. 重试会存在链路放大的效应
         - 假设A==>B==>C，如果B==>C失败，会返回失败给A，因为B失败了会重试N次，A失败了也会重试N次，就会导致重试次数呈现出指数倍增长（这样算起来，C被执行了N*N次）。这种放大可能会引发服务C的雪崩
      3. 重试的使用成本也比较高
         1. 如果公司没有重试机制的中间件，对于开发人员来说，基本都是写个for循环去重试（程序员在写代码时基本不会考虑重试的放大效应，这样很不安全）。公司内部出现过多次因为重试而导致的事故，一旦出事故的时候，只能通过“删除重试代码&&重新发布上线”后去掉重试，这样的缺点很明显：及时性很差
3. 常见的重试中间件的缺陷
   1. 它们通常会考虑对直接下游的保护，但是不会考虑链路级别的重试放大
   2. 因为引入了中间件，就需要业务方修改RPC调用的代码，对代码侵入性大
   3. 而且也是静态配置，需要修改配置时都需要重新上线
4. 一个完美的重试治理组件应具备的优点
   1. 能够在链路级别防止重试风暴
   2. 保证易用性，业务接入成本小
   3. 具有灵活性，能够动态调整配置
5. 重试治理实现的具体方案
   1. 接入方式: 动态配置中间件Milddleware
      1. 好处
         1. 用户不需要修改RPC代码（内部实现细节对用户透明，对代码无侵入），只需要在服务中引入一个全局的Middleware即可
         2. 支持在web页面动态调整配置（一次接入后就具备动态配置的能力）
            1. 配置的维度按照RPC调用特点，选定[调用方服务，调用方集群，被调用服务，被调用方法]为一个元组，按照元组进行配置
      2. 原理
         1. Milddleware封装了读取配置的方法
         2. 在RPC调用时，会自动读取配置，然后根据配置指定的策略来执行
   2. 退避策略: 决定等待多久之后再重试
      1. 背景：一个重试组件包含的基本功能中，除了重试次数和总延时，还需要有退避策略
         1. 对于一些“暂时性的错误”，如网络抖动等，可能立即重试后还会失败，通常需要等待一小会再重试的成功率会较高
         2. 打散上游的充实时间，避免因为同时都重试而导致下游的流量瞬间徒增
      2. 退避策略种类
         1. 线性退避：每次等待固定时间后重试
         2. 随机退避：在一定范围内随机等待一个时间后重试
         3. 指数退避：连续重试时，每次等待时间都是前一次的倍数
   3. 防止retry storm: 重试熔断限制大胆点放大倍数
      1. 限制单点重试: 基于熔断器的思想，限制“请求失败/请求成功的比率”，给重试增加熔断功能
         - 以滑动窗口熔断器的方法来举例
            1. 为每一类RPC调用维护一个定长的滑动窗口，每个窗口bucket记录了1s内RPC请求结果数据（成功次数、失败次数）。新1s到来时，生成新的窗口bucket，淘汰旧的窗口bucket（即窗口向前滑动1次）
            2. 当新的请求执行失败时，计算窗口内“请求失败/请求成功的比率”，根据失败率是否超过阈值来决定是否可以重试（默认阈值是0.1，即下游最多承受1.1倍的QPS）
    4. 限制链路重试
       1. 结论
          1. 通过重试错误标志链路回传的方式来保证只有最下层发生重试
          2. 通过重试请求 flag 链路下传的方式来保证对重试请求不重试
       2. 解释
          1. 之前说过，在多级链路中，如果每次RPC调用都配置重试，就会导致调用量呈现出指数级扩大
          2. 虽然有了重试熔断后（单节点重试扩大限制在1.1倍QPS），但是还是会随着链路的级数的增长而扩大调用次数（即，每个链路允许增长1.1倍，随着链路的加深，就是1.1的N次方倍）==>所以，还是要考虑链路增长带来重试扩张的风险
       3. 解决方案
          1. 参考Google-SRE的实现方法，采用特殊错误码方式限制链路重试
             1. 原理
                1. 统一约定一个特殊的错误码，它表示调用失败，但别重试
                2. 任何一级重试失败后，生成该错误码并返回给上层
                3. 上层收到该错误码后，停止对下游进行重试，并将错误码再次传给自己的上层
             2. 分析
                1. 该方式理想情况下，只有最下层发生重试，它的上游收到错误码后都不会重试，链路整体放大倍数也就是 r 倍(单层的重试次数)
                2. （超时导致方案失效）在测试错误码上传方案时，发现超时情况下，可能会导致传递错误码的方案失效
                   1. 场景分析: A==>B==>C
                      1. 假设B==>C超时，B会再次重试请求C
                      2. 这时候很可能A==>B也超时了，所以A没有拿到B返回的错误码，那么A会继续重试调用B（此时，虽然B生成了调用C的错误码，但是却不能传递给A。这种情况下，A还是会重试B。最极端的情况，如果每个链路都超时了，那么上层拿不到下层调用返回的错误码，那么每层都会继续调用下层，那么，还是会出现链路指数扩大的效应）
                   2. 解决方案分析
                      - 错误码是“从下向上”解决链路重试扩大的影响，但是因为下层返回的错误，上层却接收不到，那么，可以反其道而行之，采用请求中携带超时请求标记的方式“从上向下”来解决
                    1. 解决方案原理: Request携带retry flag方案
                       1. 在A==>B==>C的链路上，A向B请求时，如果超时了，那么，A在重试B的时候，就在Request上携带retry flag标记
                       2. B收到A请求后，先查看Request中是否携带了retry flag标记，
                          1. 如果携带了，即使B调用C失败了，B也不会去重试C
                          2. 如果未携带，B调用C失败后会重试C
                       3. 同时，B、C也会把这个retry flag层层下传
                       - 这样，即使A因为超时而拿不到B的返回，A对B发出重试请求后，B能感知到并且不会对C重试，这样A最多请求R次，B最多请求R+R-1次，C最多请求R+R+R-2次，如果后面还有更下层的话，第i层最多请求i*R-(i-1)次。最坏的情况下是倍数增长，不是指数增长了 
                    2. (超时方案优化):①Backup-Request机制:提前重试，降低无效重试，提高请求成功率 ②结合DDL:控制无效重试
                       1. 背景：在超时重试的场景中，虽然给重试加了retry flag能防止链路指数扩大的问题，但是却不能提高请求的成功率。例如下面的场景：假如A和B的超时时间都是1000ms，当C负载很高导致B访问C超时，这是B会重试C，但是时间已经超过了1000ms，此时A也超时了（A超时后就会断开和B的链接），所以B这次重试C不管是否成功都是无用功，从A的角度上看，本次请求已经失败了（那么，B重试调用C，就是无用的重试）
                       2. 分析：这种情况本质原因是因为链路上的超时时间设置的不合理，上游和下游的超时时间设置的一样，甚至上游超时时间设置的比下游还小。==>在实际情况中业务一般都没有专门配置过RPC超时时间，所以可能上下游采用的超时时间都是默认配置的==>所以，需要一个机制来优化超时情况下的稳定性，并“减少无用的重试”（引出Backup Request机制）
                          1. Backup-Request机制（详细参考链接）
                    3. 结合DDL(Deadlne Request调用链路超时): 控制无效重试
                       1. 原理：在 RPC 请求调用链中会带上超时时间，并且每经过一层就减去该层处理的时间，如果剩下的时间已经小于等于 0 ，则可以不需要再请求下游，直接返回失败
                       2. 优点：减少对下游的无效调用
