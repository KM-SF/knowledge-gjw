# 前言

写在最前，本文主要以知识框架为主，根据自己对知识掌握的情况，进行知识点的梳理（有的知识点实际上上篇幅很大，但是由于自己已经理解，就没有详细叙述）。

- 为什么redis不能代替SQL进行数据存储

  MYSQL是关系型数据库，大部分数据是存储在磁盘上的，以二维表格存储；Redis是非关系型数据库，存放在内存中，以KV存储，一般，当并发量大时，且读很多时，采用Redis降低读压力，Redis一般存放热点数据

---

#  1. 底层数据结构

## 1.1. 简单动态字符串SDS

```C++
struct sds{
	int len;     // buf数组已经使用字符串的长度
	int free;    // buf数组未使用的长度
	char buf[];  // 保存字符串
};
```

### 1.1.1. 为什么要使用SDS，而不使用C字符串

- 背景
  - Redis作为缓存数据库，`数据经常会被修改`，造成`内存重分配`，影响性能。
- 原因详述
  1. SDS有len成员变量，可以在**O(1)**的时间复杂度**获取长度信息**
     - 即使反复执行strlen命令，也不会对系统性能造成任何影响
  2. 更安全：杜绝**缓冲区溢出**
     - 当SDS执行strcat/strcpy等函数时，会先检查free是否够用，不够用时，就扩增
  3. 减少**重分配次数**
     - **扩增**：SDS会多分配free的空间，当需要扩容时，若free空间足够，直接改变len/free的值就可以
     - **缩短**：缩短时，直接修改free的值，不需要释放旧空间，申请小的新空间存放新字符串

## 1.2. 哈希表

### 1.2.1. 数据结构

```c
// 哈希表
typedef struct dictEntry {
	void* key;  // 键
	union {     // 值
		void* val;
		uint64_t u64;
		int64_t  s64;
	} v;
	struct dictEntry* next; // 指向下一个哈希节点，形成链表
}dictEntry_t;

struct dictht {
	dictEntry_t **table;  // 数组，每个元素都是dictEntry_t*，它是一个链表头，所有冲突的key挂在相同链表上
	unsigned long size;   // 哈希表容量大小
	unsigned long used;   // 当前已经使用大小
}
```

```c
// 字典
struct dict {
	dictht ht[2];   // 2个哈希表: ht[0]正常情况下使用, ht[1]在rehash时使用
    int rehashidx;  // rehash索引 (没进行rehash时，该值为-1)
}
```

### 1.2.2. rehash（重新散列）

- 背景

  - 哈希表中键值对的增加/减少，都可能导致rehash（为了使哈希表的 `负载因子` 维持在合理的范围内）：一般进行2倍扩充（算法导论中的平摊分析）

- rehash过程（渐进式rehash）

  - ht[1]分配空间，新建一个空的哈希表
  - rehash索引计数器（**rehash_index**），由-1变为0，表示rehash正式开始
  - 将ht[0]中的元素，rehash重新散列到ht[1]上
    - 每次一个(key,value)键值对rehash成功后，rehash索引计数器都+1
  - 当所有的ht[0]都rehash到ht[1]中后，ht[0]被清空，此时将ht[0],ht[1]**交换**，rehash结束，最后将rehash索引设为-1

  :slightly_smiling_face:在rehash过程中，**新增加的(key,value)键值对**，怎么处理？

  - 答：会直接rehash到ht[1]上，这样做，会保证ht[0]只减不增

   rehash过程，是在增删改查时，一点点的将hash[0]上的数据，rehash到hash[1]上，将rehash的过程平摊到各个crud过程中，不会对redis造成阻塞

## 1.3. 压缩列表ziplist

- 使用场景

  - 列表键、哈希键: 含有少数的键，且键是“短整型”、“短字符串”

- 优点

  - 节省内存，实现简单，是连续内存块的顺序存储（有点像变长数组，它通过长度划分每个节点）

- 每个 `压缩列表节点` 构成

  - 前一个节点的长度pre_len 当前节点的长度、类型 
  - 当前节点的数据内容

- 连锁更新

  - 当插入和删除元素时，可能会导致连锁更新。

     ① （全small）原ziplist节点都是长度小于256：当在idx插入大于256的节点时，idx+1后面的节点e1的成员pre_len无法保存前一个节点的长度，因此，要重分配内存。这样e1内存就扩增了，因为是顺序存储，所以e2、e3后面的元素都要向后移动（更新） 

    ② （big1、small、big2）：当删除small时，将会引起big2后面的节点连锁更新



## 1.4. 跳跃表skipList

- 结构

  - 是一个**多层次**的链表，每层节点的**next跨度**大小都不同，从上到下依次减小

- 时间复杂度

  - 性能可以和AVL树媲美，且实现简单

  - 最好O（lgN）
  - 最差O（N） 

- 使用场景

  - zset有序集合键

### 1.4.1. Redis为什么使用skiplist，不使用红黑树

1. **范围查找**的时候，平衡树比skiplist操作要复杂。

   > 在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。
   >
   > 而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。

2. 平衡树的插入和删除操作可能**引发子树的调整**，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。

3. 从**内存占用**上来说，skiplist比平衡树更灵活一些。

   一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。

4. 查找单个key，skiplist和平衡树的时间复杂度都为O(logn)，大体相当

5. 从**算法实现难度**上来比较，skiplist比平衡树要简单得多。

#  2. Redis五种数据结构

- 字符串键string |
  - 字符串类型的value最大能容纳**512M** 
- 列表键         
  - ziplist
  - linklist               
- 哈希键         
  - ziplist
  - hash-table            
- 集合           
  - intset
  - hash-table
- 有序集合键     
  - ziplist
  - 跳跃表                 
- 位图键 
  - bitmap                          

#  3. 删除机制

  1. 为什么要删除key
     1. redis是内存数据库，对于过期key，要释放空间
  2. 删除key策略
     1. 随机
     2. LRU：数据刚刚被访问，这个数据是热数据，还会再次被访问
     3. LFU：在LRU基础上，为每个数据增加一个访问计数器
  3. 删除key时机
     1. 定时删除机制
        1. 优缺点：删除及时；消耗cpu
     2. 惰性删除机制
        1. 原理：一个数据过期后，并不会立即删除，而是等到再有请求来读取这个key时，对数据进行检查，如果发现数据已经过期了，再删除这个数据
        2. 优缺点：不消耗cpu；对于用不到的数据，不尽快删除，会占据内存资源
  4. redis4.0新特性：Lazy Free（惰性删除、延时释放）
     1. 出现原因：从根本上上解决大key(元素较多集合类型)删除的风险
     2. 定义：当删除key时，redis提供异步延时释放key内存的功能，把key释放操作放在bio(background I/O)单独的子线程处理，减少删除大key对redis主线程的阻塞
     3. 为什么需要lazy-free：redis是单线程程序，当运行一个消耗较大的请求，会导致所有请求排队等待
        - 在redis4.0之前，没有lazy-free，DBA只能通过取巧的方法，类似scan big key，每次删除100个元素；但是面对“被动删除键”的场景，这种取巧的删除就无能为力了
     4. lazy-free的使用分为2类
        1. 主动删除：unlink
        2. 被动删除（与4种配置有关）
           1. lazyfree-lazy-eviction：redis内存达到maxmeory && 设有淘汰策略
           2. lazyfree-lazy-expire：设有TTL的key，达到过期后
           3. slave-lazy-flush：salve全量数据同步时，slave在加载master的rdb文件前，会运行flushall清理自己的数据
           4. lazyfree-lazy-server-del：隐式del操作，如rename

# 4. 持久化RDB/AOF

- 背景
  - Redis是内存数据库，数据保存在内存中，但是内存数据容易丢失，对此，Redis提供了持久化机制：RDB（Redis DataBase）\AOF（Append only file）
  - redis宕机了，如何保证数据不丢失

## 4.1. RDB

rdb备份，是每次将数据库中的所有键值对，保存到文件中

在指定时间间隔内，将内存中的数据和操作，通过【快照】的方式保存到RDB文件

1. rdb备份会阻塞主线程么？
   1. save：在主线程执行，导致阻塞
   2. bgsave：创建子进程，专门用于写入rdb文件，避免主线程阻塞 ==> 引出新的问题，bgsave在执行过程中，redis还能接收新的写请求么？==> 答：能，那redis是怎么处理的呢？==> 借助操作系统的cow(copy-on-write)写时拷贝技术，在执行快照的同时，能正常处理写操作 (COW: 保证主进程的数据是最新的，子进程的数据是快照点的数据)
      1. bgsave子进程是由主线程fork生成的，可以共享主线程的所有内存数据。bgsave子进程运行后，开始读取主线程的内存数据，备份写入rdb文件
      2. 当主线程对某个键值对C执行了“修改”操作，那么这块数据就会被复制一份，生成该数据的副本C'：然后，（1）主线程在这个数据副本C'上进行修改，（2）bgsave子进程可以继续把原来的数据C写入到rdb文件。 ==> 这样，既保证了子进程bgsave了某个时间点的快照，又保证了主线程能处理新的写操作

- RDB三种触发机制

  - SAVE： save会阻塞Redis服务器进程，Redis不能处理客户端的其他命令请求，直到RDB文件创建完毕为止
  - 手动触发：BGSAVE会创建一个**子进程**，更新RDB文件，父进程可以继续处理请求 
  - 自动触发：通过Redis配置文件来完成
    - save m n：在m秒内数据集存在n次修改时，自动触发bgsave。
- 优点
  > RDB文件紧凑、全量备份，非常适合于备份和灾难恢复
  >
  > RDB恢复速度比AOF快（AOF要进行重放）
- 缺点
  > 不安全：会丢失时间间隔内的数据
  >
  > 全量备份：快照方式备份，耗用时间多
  >
  > fork子进程开销：每次保存RDB文件时，都需要fork一个子进程来持久化，性能开销较大

## 4.2. AOF

Redis将每次更新写操作命令，都以**追加方式**写入AOF文件。重启时，只需要从头到尾执行一次AOF中的指令，可以恢复数据

1. aof日志的书写模式不是采用WAL：说到日志，我们比较熟悉的是写前日志（write ahead log，WAL），即：在实际写数据库之前，先写日志，以便故障时进行恢复；不过aof，刚好相反，它是先将数据写入内存，后写日志
   1. redis的aof为什么采用后写日志模式呢？
      1. 传统数据库日志，例如redolog，记录的是修改后的数据，而aof日志的内容，记录的是redis收到的每一条命令，这些命令是以文本的形式保存的
      2. 为了避免额外的检查开销，redis向aof写入日志的时候，并不会先对这些命令进行语法检查。所以，如果先写日志在执行命令的话，日志中就可能出现了错误的命令，redis在使用日志恢复数据时，就可能会出错  
      3. 在命令执行后才执行记录日志，所以不会阻塞当前的写操作
   2. aof后写日志存在2个风险点
      1. 如果执行完一个命令，还没来得及写日志就宕机了，那么，这个命令修改的数据就会丢失
      2. aof日志是在主线程中执行的，如果把日志文件写入磁盘时，磁盘写压力大，就会导致刷盘很慢，进而导致后续的操作也无法执行了
2. aof 3种写回策略（配置项appendfsync）
   1. always，同步写回：每个命令执行完，立马同步日志写回磁盘
      1. 可以做到基本不丢数据，但是它在执行写命令后都会有一个同步慢速的落盘操作，不可避免的会影响主线程性能
      2. 最多可能丢失1条数据
   2. everySec，每秒写回
   3. no，操作系统控制的写回：每个写命令执行完成，只是把日志写到aof文件的内存缓冲区，由os决定何时将缓冲区内容写回磁盘
3. aof的优点和缺点
   1. 优点：增量备份；需要持久化的数据不大
   2. 缺点：
      1. 发生宕机，aof中记录的命令要一个个被重新执行，整个恢复过程十分缓慢
      2. 每条命令都写入aof文件，文件会变得很大，占据磁盘空间+写入效率也会变低
         1. rewrite机制：redis根据数据库的现状创建一个新的aof文件，即，读取数据库中所有的键值对，然后对每个键值对用一条命令记录它的写入（aof旧文件的多条命令，会变成一条命令）
            1. 为了防止**AOF文件过大**，采用了rewrite机制。（将对同一个key的操作，合并成一个语句，写入AOF文件）
            2. AOF 的 rewrite，是放在 **子进程** 里执行的: 在重写期间，服务器主进程依然能处理命令请求
         2. rewrite重写缓冲区：**子进程rewrite**，存在一个问题：因为子进程在rewrite期间，主进程可能会收到客户端的更新，导致主进程数据和重写后的AOF文件<u>数据不一致</u>。如何在保证主进程和子进程数据一致性的前提下，允许主进程继续提供服务？ 
            1. 和aof日志由主线程写回不一样，rewrite是由后台子进程bgwriteaof来完成的
            2. rewrite过程总结为：“一个拷贝，两处日志”
               1. 一个拷贝：指，每次执行rewrite时，主线程fork出后台的bgwriteaof子进程。此时，fork会把主线程的内存拷贝一份给bgwriteaof子进程；然后，bgwriteaof子进程就可以在不影响主线程的基础上，逐一将新操作记录到rewrite日志
               2. 两处日志: 子进程重写后的日志 + 主进程重写缓冲区的日志
                  1. 为什么呢？ 因为主线程未阻塞，仍然可以处理新来的请求。此时，如果有新的写操作，redis主线程接收到之后，子进程重写的日志中没有新的内容，可能会造成数据不一致
                  2. 解决方案：redis会把主线程新处理的写操作保存到重写缓冲区，即使宕机，可以redis积压缓冲区中的数据进行恢复
                     - 为了解决这个问题，AOF设置了**重写缓冲区**（在主进程创建子进程后，该重写缓冲区开始被使用）
                       1. 在子进程重写期间，<u>主进程（服务器）</u>要执行下面3个工作
                            - 接收并执行客户端发来的命令请求
                            - 将执行后的写命令，追加写入AOF重写缓冲区
                       2. 当子进程执行完重写后，会向主进程发送信号，此时，父进程调用该信号的处理函数，执行下面的工作: 将AOF重写缓冲区中的数据，写入新的AOF文件(此时，aof文件的数据 = 被子进程rewrite后的数据 + 重写缓冲区的数据)

## 4.3. rdb和aof对比

- 优点
  - AOF可以更好的保护数据不丢失
    - 一般AOF更新时间设置为1s，通过一个后台线程执行一次fsync，最多丢失1s的数据
- 缺点

  - <u>相同数据集，AOF文件要**远大于**RDB文件</u>，恢复速度要重放（慢于RDB）

  - 一直更新写操作，会使AOF文件激增，极端场景下，会对硬盘空间造成压力 


## 4.4. 常用的备份策略：rdb+aof

假设，rdb备份时间为N，执行过程如下
1. 时间到达N时，执行第一次rdb全量备份，得到checkpoint1
2. 在时间区间(N,2N)时，产生的增量数据，记录到aof文件中
3. 当时间到达2N时，执行第二次rdb全量备份的过程为：在checkpoint1的基础上，重新执行aof日志记录的操作，生成checkpoint2，清空aof


# 5. 高可用

- 宕机恢复: 当一台服务器宕机停止服务后，对业务及用户毫无影响

## 5.1. 主从复制

- 优点
  > 正常情况下，主机提供服务，并将数据同步到备份机器；当主机宕机后，备机立即开始服务 。
  >
  > master宕机后，通过<u>选举投票</u>方式选择出新的master，继续提供服务。
  >
  > 实现读写分离，提高并发性

**Redis的复制功能，分为 同步 和 命令传播**

### 5.1.1. 同步

- **主从复制的过程**

  - 从服务器向主服务器发送SYNC命令

  - 主服务器收到SYNC命令后

    - 执行BGSAVE，在后台<u>生成RDB</u>文件
    - 使用一个<u>缓冲区记录</u>从现在开始执行所有的新的更新命令

  - 主服务器

    - 执行BGSAVE后，会将RDB文件发送给从服务器
    - 将<u>缓冲区中的新更新命令</u>，发送给从服务器

  - 从服务器

    - 收到RDB后，加载RDB文件同步数据

    - 执行收到的缓冲区更新命令，此时，数据与主服务器一致

- **旧版本复制功能的缺陷（断线后，重新复制）**

  - 网络断线后，会重新全量复制

- **新版本解决了断线重复制问题**

  核心: <u>复制积压缓冲区</u>、<u>主服务器和从服务器都维护了自己的复制偏移量</u>

  - 当主服务器<u>向</u>从服务器器<u>传播N个字节的数据后</u>，会把自己的复制偏移量+N
  - 从服务器<u>收到</u>主服务器<u>传来的N个字节且更新成功后</u>，也会将自己的复制偏移量+N

  因此，通过**主从服务器的复制偏移量**，就能知道此时二者是否处于一致性状态！

  - 主服务器，还维护了一个<u>定长</u>的复制积压缓冲区，每次向从服务器发送更新数据时，同时会向复制积压缓冲区写入数据
    - 当连接断开后，从服务器<u>判断自己的复制偏移量offset是否在复制积压缓冲区</u>中
      - 如果在，执行部分复制
      - 如果不在，执行全量复制


- 主从库数据第一次同步的三个阶段

  1. 第一阶段：建立连接，协商同步
     1. 从库告诉主库建立连接，并发送psync命令告诉主库即将进行数据同步。psync命令包含了主库id、复制offset两个参数
     2. 主库收到psync命令后，会用fullresync（第一阶段，是采用rdb的方式，进行全量复制）响应命令带上两个参数（主库id、主库目前的复制offset）
  2. 第二阶段：主库将所有数据同步给从库，从库接收到数据后，在本地完成数据加载
        1. 主库执行bgsave，生成rdb文件，将rdb文件发送给从库
        2. 从库接收到rdb文件后，先清空当前数据库，然后加载rdb文件
  3. 第三阶段：主库会把第二阶段中执行的新的写入命令，重新发给从库
     1. 当主库完成rdb文件发送后，就会把此时replication buffer中修改的操作发送给从库
     2. 从库再重新执行这些操作，这样一来，主从库就实现了数据一致

- 主从同步面临的问题：网络闪断

   缺点：在redis2.8之前，如果主从库在命令传播时出现了网络闪断，那么从库就会和主库重新进行一次全量复制，开销非常大

   从redis2.8开始，网络闪断后，主从库会采用增量复制的方式继续同步（即，增量复制只是把网络闪断期间收到的增量命令，同步给从库）

   1. 网络闪断后，主库会把闪断期间收到的更新命令，写入到两个缓冲区
      1. replication buffer
         1. 上面已经提到过，bgsave执行期间，保存增量更新的数据
      2. repl_backlog_buffer(复制积压缓冲区——定长环形缓冲区)
         1. 主库记录自己写到的位置，从库记录自己读到的位置
         2. 网络闪断，增量更新的数据
   2. 网络闪断结束后，从库会根据repl_backlog_buffer环形缓冲区的r_idx、w_idx，copy增量数据
   3. 注意: 当复制积压缓冲区被写满时，会全量复制RDB

##  5.2. 哨兵

- 作用: 主库挂了，通过(redis主从同步+哨兵机制)，不间断服务，实现主从库自动切换的关键机制

- 原理：哨兵将会监控集群中所有的节点；一般为了防止单哨兵节点故障，将配置多个哨兵协同合作。

- 切换过程
  1. <u>主观下线</u>：哨兵A检测到主节点下线后，将不会立即切换主节点，而是认为它客观下线 
  2. <u>询问</u>：哨兵A会询问<u>监听该主节点的其他哨兵</u>，收集汇总信息，当有足够多的主观下限信息时，判断是否为客观下线
  3. <u>选取新领头哨兵</u>：当有一个哨兵判断为客观下限后，将会选举出领头哨兵，由它进行切换主节点操作

- 缺点

  - 运维复杂
  - 哨兵选主期间，不能对外提供服务（因此如果Master宕机后，不支持并发）

1. 主从复制面临的3个问题
   1. 主库真的挂了么？
   2. 该选择那个从库作为主库？
   3. 怎么把新主库的相关信息通知给从库和客户端呢？
2. 哨兵机制的基本流程 ==> 哨兵机制是实现主从库自动切换的关键机制，它有效解决了主从复制模式下故障转移的3个问题。哨兵主要负责的就是3个任务，如下:
   1. 监控：哨兵在运行时，周期性的给所有主从库发送ping命令
      1. 主观下线：某一个哨兵判断主库处于主观下线状态
      2. 客观下线：询问哨兵集群中的其他哨兵，主库是否下线，当>=(n/2+1)个哨兵下线后，认为客观下线
   2. 选主：“筛选+打分”，按照一定的规则，给从库打分，从得分最高的从库中选择一个作为新的主
      1. 筛选+打分
         1. 从库在线
         2. 之前的网络连接状态
         3. 从库优先级(salve-proxy配置项)、从库复制进度、从库ID号码
      2. 选主：投票机制，quorum 
   3. 通知
        1. 将新主库的连接信息发送给其他从库，让从库执行replicaof命令，和新主库建立连接，执行数据复制
        2. 将新主库的链接信息发送给客户端，让客户端的请求发到新主库 
3. 哨兵集群
   1. 引入：哨兵集群的配置，只需要设置主库的IP和端口，并没有配置其他哨兵的连接信息
   2. 问题：这些哨兵不知道彼此的地址，又是怎么组成集群的呢？==>哨兵集群的组成和运行机制
   3. 哨兵集群的组成和运行机制：基于发布订阅的哨兵集群组成
      1. 哨兵实例之间可以相互发现，归功于redis的发布订阅机制
      2. 哨兵只要和主库建立起连接，就可以在主库上发布消息了，比如：发布它自己的连接信息（IP+PORT），同时，它也可以在从库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布订阅操作后，它们之间就能知道彼此的IP+port。


##  5.3. Redis集群

一个集群通常有多个服务器节点组成：①最开始时，各个服务器节点是相互独立的；②之后，将各个节点连接起来

### 5.3.1. 槽指派

1. 一个redis集群共有16384个哈希槽（这类似于数据分区），每个键值对都根据它的key，映射到一个哈希槽中，哈希槽计算公式 = crc16(key)%16384
2. 假设集群有N个redis实例，每个实例上槽的个数就是16384/N
3. 所有的槽全部分配到redis实例后，redis集群才能真正的对外提供服务。只要有任何一个槽发生问题，整个集群都不可用


将槽分配到集群中某个节点的算法，一般采用取模算法、[一致性哈希算法](https://blog.csdn.net/weixin_36750623/article/details/84993780)。

#### 5.3.1.1. Redis怎么分片的
结论：集群 + 槽位， Redis集群没有使用一致性hash，而是引入了哈希槽的概念。

公式：（CRC16(key) % 16384） % 节点数


### 5.3.2. 在集群中执行命令

- 当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽。
- case1: 如果键所在的槽正好就指派给当前节点，那么当前节点直接执行该命令
- case2: 如果键所在的槽没有指派给当前节点，那么节点会向客户端返回一个MOVED错误，指引客户端转向（redirect）至正确的节点，并再次发送之前想要执行的命令

### 5.3.3. 重新分片

定义：将任意数量已经指派给某个节点的槽，改为指派给另一个节点，并且相关槽所属的键值对也会从源节点移动到目标节点。

- 重新分片可以[在线]进行，即：在重新分片过程中，<u>集群不需要下线</u>，并且<u>源节点和目标节点都可以继续处理命令请求</u>

### 5.3.4. 复制

上面已经知道，集群中某个节点维护了某个区域的槽

- 为了防止该节点挂掉，一般对该节点配置主从关系，形成主从复制结构
- 从节点会复制主节点的槽，当某个主节点故障了，因为<u>从节点已经复制了它的槽</u>，所以该从节点将会升级为主节点，继续服务。（与哨兵相比，在此期间，不会停止服务）

### 5.3.5. 故障检测
- 故障检测：每个节点会<u>定时</u>向集群中其他节点发送<u>ping</u>，<u>检测对方是否在线</u>; 
- 集群中各个节点会互相发送消息，<u>交换</u>集群中<u>各个节点的状态信息</u>;
- 当某个<u>主节点x</u>疑似下线的数<u>过半</u>时，将会被标记为已下线，之后，会<u>广播</u>给集群中所有节点，告诉它们节点x已经下线

### 5.3.6. 故障转移/raft选主算法


1. 通过raft选主算法，会从下线的主节点的从节点中选取一个，让它成为新的主节点
2. 新节点将会广播一条pong消息，通知其他节点自己已经变成了主节点
3. 新主节点将接管原来已经下线的主节点，继续提供服务

##  5.4. Redis分区/分片(sharding)

1. 定义：分区是分割数据到多个Redis实例的处理过程，因此每个实例只保存key的一个子集（一个分区，就是一个redis实例）
   - 例如：可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个 CPU，你可以考虑一下分片(shard)。
2. 分区的优势
   1. 通过利用多台计算机内存的和值，允许我们构造更大的数据库。
   2. 通过多核和多台计算机，允许我们扩展计算能力；通过多台计算机和网络适配器，允许我们扩展网络带宽。
3. 分区的不足
   1. 涉及多个key的操作通常是不被支持的。举例来说，当两个set映射到不同的redis实例上时，你就不能对这两个set执行交集操作。
   2. 涉及多个key的redis事务不能使用
   3. 当使用分区时，数据处理较为复杂，比如你需要处理多个rdb/aof文件，并且从多个实例和主机备份持久化文件。
   4. 增加或删除容量也比较复杂。redis集群大多数支持在运行时增加、删除节点的透明数据平衡的能力，但是类似于客户端分区、代理等其他系统则不支持这项特性。然而，一种叫做presharding的技术对此是有帮助的


# 6. Redis扩展特性

## 6.1. 发布订阅模式

- 客户端订阅服务端的频道

- 当服务端向该频道中发送消息时，频道中所有的客户端都会收到该消息，执行相应的动作 

## 6.2. 事务

### 6.2.1. SQL/Redis事务对比

SQL和Redis的事务有本质的区别

- SQL事务原理
  - innodb引擎支持的事务，采用**Redo log + Undo log**来实现
- Redis事务原理
  - 使用 **乐观锁**，只负责<u>监听key</u>有没有被改动。
    - 采用watch监听某个key
    - 在执行命令时，检查该被监视的key是否已经被修改
    - 如果该key时被改动，那么事务将会被打断

【补充】与SQL事务最大的区别，<u>Redis不支持事务回滚</u>，即使事务在执行过程中出错，也不会回滚，将会一直执行下去，直到事务结束。 因为，开发者认为，事务执行失败，很少会在实际生产环境中出现。

## 6.3. 索引

 Redis没有实现索引，如果需要索引，需要用户自己设置并实现之 

---

# 7. Redis: 单线程？

[Redis 6.0 的那些事](https://www.cnblogs.com/madashu/p/12832766.html)

## 7.1. Redis单线程？多线程？

之前说Redis是单线程，指的是Redis的`处理客户端请求事件`的主线程是“单线程的”，其实还是有一些后台线程在做任务。

- 主线程
  - Redis在<u>处理客户端请求时（获取命令、解析命令、执行、返回内容）</u>等操作都是由一个顺序串行的主线程处理的，这就是所谓的“单线程”。
- 后台线程
  - 清理脏数据、无用连接释放、大key的删除

## 7.2. Redis6.0之前为什么之前一直不使用多线程？

**官方回应**：Redis几乎不存在CPU称为瓶颈的情况，主要受限于**内存/网络**。单机QPS可以达到**100万**。

- 多线程难以维护性
  - 增加系统复杂度：单线程的惰性删除、Rehash等操作都可以<u>无锁实现</u>
  - 存在线程切换，<u>加锁解锁</u>带来的性能消耗
- 集群：单机如果实在不行，还可以使用多个Redis服务器组成<u>集群</u>，也能在一定程度上解决性能上的压力


## 7.3. 为什么Redis单线程模型处理速度如此快？

Redis通过使用pipelining单机每秒可以处理100万个请求（QPS，百万级别）

1. 内存数据库，所有操作都在内存上完成
2. “完美”的数据结构的设计，键值对按照一定的数据结构促织，操作键值对最终都是对数据结构进行增删改查操作，所以高效的数据结构是redis快速处理数据的基础
3. Reactor（IO）多路复用模型
   - 服务器接收/处理客户端发来的请求命令是单线程的，它采用了IO多路复用能够同时监听多个事件的到来，当事件到来后，会将就绪事件挂到激活队列中，然后依次执行

## 7.4. 为什么Redis要引入多线程呢？

- 随着业务场景越来越复杂，数据量越来越大，需要更大的QPS
- 使用多个Redis服务器组成集群，需要对它们进行维护，维护代价大
- <u>多线程</u>能够充分的利用<u>多核CPU</u>


## 7.5. Redis6.0默认开启多线程么？如何开启和设置线程数？

1. 默认多线程模式是关闭的

   ```python
   # io-threads 4
   ```

2. 官方建议

   - 4核机器建议设置为2或3，8核建议设置为6.<u>（线程数一定要小于机器核数）</u>
   - 还需要注意的是，<u>线程数并不是越大越好</u>，官方认为超过了8个基本就没什么意义了


3. **开启多线程后，是否会存在线程并发安全问题？**

   ①只是用来<u>处理网络数据的读写和协议解析</u>

   ②<u>执行命令仍然是主线程顺序执行</u>。

   ==> 所以，不需要去考虑控制 key、lua、事务，LPUSH/LPOP 等等的并发及线程安全问题。



# 8. 实战篇

## 8.1. 数据倾斜（大key+热key）

1. 数据量分配倾斜：redis实例上的数据分布不均匀，某个实例上的数据特别多
   1. 原因
      1. 大key导致倾斜
         1. 解决方案：
            1. 在业务侧保证生成数据时，避免过多的数据保存在一个key中
            2. 一个key，拆分成多个key，分散存在不同的redis实例上
      2. 运维人员slot分配不均衡导致倾斜
      3. Hash Tag导致倾斜
         1. Hash Tah
            1. Hash Tag指在键值对对key中的一堆花括号{}。这对括号会把key的一部分括起来，客户端在计算key的crc16值时，只会对Hash Tag花括号中的key内容进行计算。（如果没使用Hash Tag的话，客户端计算整个key的crc16的值）==> 导致大量的key会集中到某个实例中
            2. Hash Tag使用场景：在redis cluster，支持事务操作和范围查询。==>因为redis并不支持跨库事务处理，也不支持跨库范围查询
         2. 解决方案
            1. 优先考虑避免数据倾斜，最好不要使用Hash Tag进行数据切片
            2. 事务和范围查询否放在客户端进行
2. 数据访问倾斜：某个redis实例上的数据是热点数据，访问十分频繁
   1. 只读热点数据
      1. 因为热点数据以服务读操作为主，所以采用“热点数据多副本”的方法来应对
      2. 具体做法：把热点数据复制多分，在每个数据副本的key中增加一个随机后缀，让它和其它副本数据不会被映射到同一个slot中（这样一来，热点数据既有多个副本同时提供服务，同时，这些副本数据的key又不一样，会被映射到不通的slot中）
   2. 有读有写热点数据
      1. 热点数据多副本方案只能针对只读热点数据，如果热点数据有读有写，为了保证多副本之间的一致性，就会带来额外的开销
      2. 具体做法
         1. 对于有读有写的热点数据，就要加redis实例

## 8.2. 集合类型的解决方案

有1亿个keys要统计，应该用哪种集合类型？

常见集合类型：{list/hash/set/zset/bitmap}

场景：一个key对应了一个数据集合

1. 手机app中的每天的用户登录信息：一天对应一系列用户id或移动设备id
2. 电商网站上商品的用户评论列表：一个商品对应了一系列评论
3. 用户在手机app上的签到打卡信息：一天对应一系列的签到记录
4. 应用网站上网页访问信息：一个网页对应一系列的访问点击

redis的集合类型的特点就是一个键对应一系列的数据，所以非常适用来存储这些数据。但是在这些场景中，除了记录信息，往往还需要对集合中的数据进行统计，例如：
1. 统计每天新增用户数、第二天留存用户数 ==> 聚合统计
   1. 使用set类型，key设置为user_{日期}，val是set集合，里面所有登陆过app的用户id
   2. 新增用户：差集  sdiffstore user_new user_{日期1} user_{日期2}
2. 统计评论列表中的最新评论 ==> 最新，显然是按照时间排序，排序统计
   1. list：包含了对某个商品所有的评论，每来一个新的评论，就Lpush插入到队头
   2. zset：最新评论的权重更大，
3. 统计近1个月连续签到打卡的用户数 ==> 二值状态统计 bitmap
   1. 用户每条的签到用1个bit位就能表示，一年的签到只用365个bit位即可
4. 在网页访问记录中，统计独立访客量 ==> 基数统计/去重统计 set/HyperLogLog

- 集合类型的解决方案
  1. 聚合统计：set
     1. 统计多个集合元素的聚合结果，包括：多个集合的交际、差集、并集
  2. 排序统计：list、zset
     1. list：按照元素进入的顺序进行排序
     2. zset：按照元素的权重来排序
  3. 二值状态统计：二值状态指集合元素的取值只有0和1两种
  4. 基数统计：统计一个集合中不重复的元素个数，即去重 set/HyperLogLog


## 8.3. redis如何保存时间序列的数据 (redis实现延时队列)

1. 时间序列数据的特点：因为时间是不回退的，所以只是插入操作；记录过的数据，无需更新
2. 查询特点
   1. 点查询：查询某个时间点
   2. 范围查询：查询一段时间内
   3. 聚合计算：如何对时间序列做聚合计算，如，每3分钟算一次最大值
3. 实现方案
   1. 方案一：基于hash和sorted set保存时间序列数据
      1. hash：查询某个时间点，某个key的val
      2. zset：查询一段时间内，将score设为时间戳
      3. 如何保证hash和zset是一个原子操作：lua 或 事务
   2. 方案二
      - 使用sorted set，使用时间戳做score，消息内容作为key，调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理
   3. 方案三：redisTimeSeries（redis专门为时间序列数据访问设计的扩展模块，支持在redis实力上直接进行聚合计算）

## 8.4. redis之消息队列解决方案 (redis实现异步队列)

消息：有序；重复幂等处理；消息可靠性

1. 基于list的消息队列解决方案
   1. 有序性：list本身按照fifo顺序对数据进行存储（LPUSH+RPOP)
   2. 重复幂等处理
   3. 消息可靠性：当消费者程序执行RPOP取出了数据，若执行程序失败or消费者程序宕机了，该消息就不存在了
      1. redis提供了BRPOPLPUSH命令，作用是
         1. 让消费程序从一个list读取消息，同时插入到备份list
         2. 这样当消费者读取消息没正常处理时，等重启后，能从备份list重新读取消息
   4. 存在的问题：生产者生产过快，导致list数据越积越多，影响性能
2. 基于Streamer的消息队列解决方案：redis专门为消息队列设计的数据类型
   1. XAdd：插入消息，保证有序，可以自动生成全局唯一ID
   2. XRead：读取消息
   3. XReadGroup：按消费组形式读取消息
   4. XPending：查询每个消费组内所有消费者已经读取但未确认的消息
   5. XAck：向消息队列确认消息处理已完成（类似于手动提交）


## 8.5. redis变慢checklist

当遇到redis变慢时，按照以下checklist依次排查

1. 获取redis实例在当前环境下的基线性能
2. redis实例运行机器内存不足，导致swap发生
3. 是否用了慢查询命令：如果是的话，使用其他命令代替慢查询命令
   1. 将聚合计算命令放在客户端做
   2. keys
4. 大量ke集中过期
5. 大key删除
   1. 使用scan命令迭代删除
   2. 对于大key的集合查询和聚合操作，可以使用scan命令在客户端完成
6. aof写回策略always，导致每个操作都同步刷写磁盘

## 8.6. 缓存3大问题

1. 缓存雪崩
   1. 原因
      1. 缓存宕机，缓存数据大面积同时失效
      2. 缓存同时到期，缓存数据大面积同时失效
   2. 应对方案
      1. 一般采用“搭建高可用集群”，防止“Redis服务器宕机”导致缓存雪崩
      2. 采用“设置不同的过期时间”：防止同一时间大量数据过期现象发生
      3. 已经出现缓存雪崩：服务限流、降级、熔断
         - “降级”，（服务降级）而向那些被拒绝的请求直接返回一个预设结果，被称为“降级”
         - “熔断”，（拒绝请求）一旦发现当前服务的请求失败率达到预设的值，就拒绝随后该服务的所有请求。
         - “限流”，（限制请求数量）当经过一段时间后，会放行该服务的一部分请求，再次统计它的请求失败率。如果此时请求失败率符合预设值，则完全打开限流开关；如果请求失败率仍然很高，那么继续拒绝该服务的所有请求，这就是所谓的“限流”。
          
2. 缓存击穿
   1. 原因
      1. 指`缓存中没有，但数据库中有的数据（一般是缓存时间到期）`，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力
   2. 应对方案
      1. 不给热点数据设置过期时间，一直保留
      2. 分布式锁
3. 缓存穿透
   1. 原因
      1. 访问缓存和数据库中都没有的数据
   2. 应对方案
      1. 布隆过滤器



在使用缓存时，一定要考虑好下面两个问题：① 如何使用缓存？② 缓存使用时注意事项？

- 使用缓存的哪种数据结构
- 缓存过期淘汰策略
- 缓存需要持久化么？持久化方式
- 缓存需要分布式么？分布式锁并发控制
- 缓存3大问题
- 缓存一致性问题

## 8.7. 缓存一致性问题

经常会有人问，缓存会出现一致性问题，怎么样解决呢？当数据发生变更时，是先更新缓存再更新数据库，还是先更新数据库再更新缓存？:slightly_smiling_face:在这里，先给个结论：这种问法就有问题，即使你先更新谁都错，都不能保证缓存一致性。


### 8.7.1. 缓存不一致场景

下面的场景介绍都是高并发场景下的。

#### 8.7.1.1. 先更新缓存，再更新数据库

显然是不行呀，缓存更新成功了，但是更新数据库却失败了，那么，每次访问数据都先访问缓存中错误的数据！

#### 8.7.1.2. 先更新数据库，再更新缓存

**case1**：更新完数据库（更新成功），再更新缓存（更新失败，导致缓存中的数据是旧值）

**case2**：多线程的顺序问题。


- 原因分析：线程A、B都更新同一个字段ID。执行过程：线程A先更新数据库ID=1，然后发了一个更新缓存ID=1的操作，但是由于网络原因，更新缓存的操作卡住了。之后线程B更新数据库ID=2，且更新成功，然后线程B更新缓存成功ID=2。此后，之前卡住的线程A的更新缓存ID=1操作执行成功。

结束时，数据库/缓存中ID的值分别是ID=2、ID=1，出现不一致！

#### 8.7.1.3. 先删除缓存，再更新数据库

上面分析了（先删除缓存在删除数据库、先删除数据库再删除缓存）都是错误的！此处引出新的思路，就是在数据发生更新前，先删除缓存，再更新数据库。

- 解决方案1（错误）：<font color=red>更新时，① 先删除缓存，② 再修改数据库。 </font>
  - 如果第②步数据库修改失败了，那么数据库中是旧数据，因为删除了缓存，所以缓存是空的。当读数据时候（缓存是空的），会去数据库中读取数据，这样并不会出现不一致性问题。
    - 备注：这样分析，该解决方案看似是没问题的，但是实际上他还是具有缺陷。:smirk:真是靠了… …，


下面分析为什么上面的解决方案还会出现问题。

1. 数据发生了变更，先删除缓存，然后去修改数据库（该操作卡了），此时，还没修改数据库。
2. 但是一个读请求过来：将先去读缓存，发现缓存空了，就去查询数据库。会查到了未修改的数据库旧值，*将旧数据放到了缓存中。*
3. 随后，修改数据库操作完成，*数据库中的内容被更新为新值了。*
4. 显然，数据库值是新的，缓存值是旧的，发生了不一致。

仔细分析，出现不一致的原因，是因为数据库更新在卡顿期间，有读到来，导致缓存中的数据是数据库中的旧值。

### 8.7.2. 解决方案 ==> 延时双删


根据上面分析出现不一致的原因 ==> 所以，解决方案就是在更新完数据库之后，添加一个善后操作，即：再次删除缓存（因为缓存中可能是旧数据）！

- 无论如何，想办法删除两次：消息队列rocketMQ（将删除任务投放到MQ，保证缓存中的数据一定能够删除）


## 8.8. [秒杀系统设计](https://www.bilibili.com/read/cv12420297)

1. 特点
   1. 瞬时并发访问量非常高
   2. 读多写少：商品库存查询 >> 库存扣减、下单操作
2. 秒杀活动分为3个阶段
   1. 第一阶段：秒杀活动前，用户不断刷新商品页
      1. 动静分离：CDN\浏览器将静态化元素缓存起来
      2. 请求拦截
         1. 验证码
         2. 恶意刷单：相同用户/IP限制次数
         3. 秒杀按钮：在活动前，先设置为灰色
   2. 秒杀活动开始
      1. 库存检查+库存扣减
         1. Lua原子操作
         2. 分布式锁
      2. 订单处理(mq)
         - 支付、商品出库、物流等多个关联操作，这些操作本身涉及到数据库中的多张表，要保证处理的事务性，需要在数据库中完成（而，此时请求压力已经不大了，数据库足以支撑） 
   3. 秒杀活动结束后
      - 活动结束后，可能还会有人访问，基本上就是有退货的用户，不过也无需关注了，流量很小 

---


# 9. Redis使用场景

## 9.1. String字符串对象

场景：统计网页/贴吧/文章阅读/浏览次数

```python
Incr article:readcnt:1001  # 对文章1001的读次数+1
```

## 9.2. Hash之淘宝商城购物车

## 9.3. List之微博公众号消息流

订阅了某个公众号，当该公众号发文章后，会推送给你！ 特点：消息的发送是有一个时间线的 

（微信朋友圈）

```python
LPAUSH msg:{小明微信号ID} 10018    # 发消息
LPAUSH msg:{小明微信号ID} 10011    # 发消息  
LRANGE msg:{小明微信号ID} 0 -1     # 查看最新的消息流列表
```

## 9.4.Bit位之日活量

场景：统计2020/10/03，登录用户数。现在系统有千万级活跃用户，如何实现日活统计，为了增强用户粘性，要上线一个连续打卡发放积分的功能，怎么实现连续打卡用户统计？

```python
将20201003Login作为key，offset作为每个用户，value 0/1表示都否登录，即：

Data    1  0  0  0  1  1  0 
Offset  0  1  2  3  4  5  ... ... 

Setbit 20201003Login 0 1 
Setbit 20201003Login 4 5 

bitcount 20201003Login 0 -1  # 统计日活

将20201003Login, 20201004Login,..., 20201007Login相与，之后再统计1的总个数 # 统计连续几日登录量
```

## 9.5. Set之微信抽奖小程序、微博点赞列表、微博关注模型	

无序不重复，放相同的元素，将会被去重（每个人点击多次抽奖，将会被去重，只视为一次抽奖）

场景1：微信抽奖小程序 

```python
SADD activity:10086 {用户ID}   # 用户点击抽奖按钮后，将加入set
SMEMBERS activity:10086       # 查看参与抽奖的所有用户
SRANDMEMBER activity:10086 2 SPOP activity:10086 2  # 随机抽取count名中奖者
```

场景2：微博点赞

```python
SADD like:{消息ID} {用户ID}      # 点赞
SREM like:{消息ID} {用户ID}      # 取消点赞
SISMEMBER like:{消息ID} {用户ID} # 检查用户是否点过赞
SMEMBERS like:{消息ID} {用户ID}  # 获取点赞的用户列表
SCARD like:{消息ID}             # 获取点赞用户总数
```

场景3：微博关注模型

James --\> {A,B,C} Kobe--\>{A,C,D,R} 

James、Kobe是两个集合Set 

```python
SINTER James Kobe      # 取出James和Kobe共同关注的人（交集） 
SISMEMBER James Jordan # 判断James集合中是否有Jordan 
SDIFF James Kobe       # James可能认识的人
```

场景4：Set实现电商商品类型的筛选 

```python
SADD brand:huawei P30 
SADD brand:xiaomi 6X 
SADD os:android P30 6X
SADD cpu:brand:intel P30 6X 
SADD ram:8G P30 6X
SINTER os:android cpu:brand:intel ram:8G  # -->{P30, 6X}
```



## 9.6. ZSet有序集合之微博热点排行榜

```python
ZINCRBY hotNews:20190722 1   # 点击新闻 
ZREVRANGE hotNews:20190722 0 10 WITH SCORES  # 展示当日排行前十
```

# 10.补充

## 10.1.分布式Redis是前期做还是后期规模上来了再做好?为什么?

1. 既然Redis是如此的轻量(单实例只使用1M内存)，为防止以后的扩容， 好的办法就是一开始就启动较多实例。
2. 即便你只有一台服务器，你也可以一开始就让Redis以分布式的 方式运行，使用分区，在同一台服务器上启动多个实例。
3. 一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已(而不用考虑重新分区的问题)。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。


## 10.2.[RedLock](https://www.cnblogs.com/rgcLOVEyaya/p/RGC_LOVE_YAYA_1003days.html)


1. 解决的问题：主从故障转移时，导致重复加锁，使得不满足加锁互斥原则（旧的主加锁成功后，新的主也能加锁成功）
   - 在clientA获取锁后，主redis复制数据到从redis过程中崩溃了，导致没有复制到从redis中，然后从redis选举出一个升级为主redis，造成新的主redis没有clientA 设置的锁，这时clientB尝试获取锁，并且能够成功获取锁，导致互斥失效
2. 实现机制：过半加锁成功，才认为加锁成功；否则加锁失败，会释放锁
   - 在TTL时间内，保证过半的节点lock成功，才加锁成功



## 10.3.扫描前缀相同的key

问题：假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来? 

答案：
1. 使用keys指令可以扫出指定模式的key列表。
   - redis关键的一个特性:redis的单线程的。keys指令会导致线程阻 塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。
2. scan指令
   - scan指令可以[无阻塞]的提取出指定模式的key列表
   - 但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。


---


- [整理了2019年40道Redis高频面试题，答案详细解析](https://www.bilibili.com/read/cv4042105/)

- [redis原理总结(很全面)](https://blog.csdn.net/wuyangyang555/article/details/82152005)
- [Redis双写一致性、并发竞争、线程模型](https://www.imooc.com/article/297496)

