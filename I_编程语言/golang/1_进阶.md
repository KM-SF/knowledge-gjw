
# 1. go的并发机制 CSP

1. 概念: CSP并发模型是在1970年左右提出的概念，属于比较新的概念，不同于传统的多线程通过共享内存来通信，CSP讲究的是“不要以共享内存的方式来通信，相反，要通过通信来共享内存”
2. Go的CSP并发模型，是通过goroutine和channel来实现的
   1. Goroutine是Go语言中并发的执行单位。有点抽象，其实就是和传统概念上的”线程“类似，可以理解为”线程“
   2. channel是Go语言中各个并发结构体(goroutine)之前的通信机制。 通俗的讲，就是各个goroutine之间通信的”管道“，有点类似于Linux中的管道。
3. 并发模型的实现原理——实际上就是GMP

## 1.1.[GMP](https://blog.csdn.net/qq_44205272/article/details/111565957) 

1. 对比: libco协程库、Go的GMP模型
   1. libco协程库，就是只有一个线程M，下面挂了多个G，
      - 缺点: 只有一个线程，无法充分的利用多核
   2. 其实，go的GMP，本质上就是有多个线程，通过引入了P，使得多个线程可以绑定多个协程队列
      1. 为了将G从M中解耦出来，引出了P的概念，P是一个协程队列，保存了每个队列的协程上下文
      2. 最原始的是，每个线程M，绑定自己的P，每个P中的队列是分开的，但是这样也存在缺点。有的M的P队列元素太多，有的M的P队列元素过少，会导致线程的负载不均衡
      3. 所以，为了使得各个线程本地队列中的G数量均衡，又引入了新的机制
         - 全局队列: 允许从其他本地队列“偷”协程，保存到自己的本地队列（偷的过程是先放到全局队列）
2. 调度器的设计策略
   - 复用线程: 避免频繁的创建、销毁线程，而是对线程的复用
   1. work stealing机制: 当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程
   2. hand off机制: 当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行
3. GMP
   1. GMP组成
      1. G: goroutine，一个执行体
      2. M: machine/thread，一个M关联了一个内核线程thread (就是一个主协程体)。M的作用是不断的去获取G
      3. P: processor处理器，代表M所需的上下文环境，也是处理用户级代码逻辑的处理器
   2. 概念
      1. M
         1. 线程想运行任务就得获取G
            1. 从P的本地队列获取G，P本地队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列偷一半放到自己P的本地队列
            2. M运行G，G执行之后，M会从P获取下一个G，不断重复下去
      2. 全局队列
         1. 需要加锁
         2. 存放等待运行的G
      3. P的本地队列
         1. 存放的也是等待运行的G，存的数量有限，不超过256个
         2. 新建G时，G优先加入到P的本地队列，如果队列满了，则会把本地队列中的一半的G移动到全局队列
   3. GMP的关系
      1. 每个M是一个thread(调度器，功能是获取G)，每个M下面挂了一个P
      2. 每个P是一个处理器，每个P下挂着一个正在执行的G0、一个未执行的G队列(称作runqueues)
   4. gmp调度器的调度过程
      1. 创建一个G
         1. 先保存到自己的本地队列
         2. 若本地队列满，则将本地队列一半的G迁移到全局队列
      2. M获取G去执行
         1. 先从本地队列获取
         2. 获取不到去全局队列获取
         3. 再获取不到，去其他M的P中“偷”
      3. M阻塞的处理方式: 当M发生了syscall或其他阻塞操作，M会阻塞
         - 如果当前有一些G正在执行，runtime会把这个线程M从P中摘除，然后再创建新的M为这个P提供服务

## 1.2.[G\M\P数量限制](https://blog.csdn.net/pyf09/article/details/114692985)

Goroutine调度器和 OS 调度器是通过M结合起来的，每个M都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行

1. P的数量
   - 环境变量GOMAXPROCS 、 runtime.GOMAXPROCS()方法
   - Go1.5之后GOMAXPROCS被默认设置可用的核数
   - 这意味着在程序执行的任意时刻都只有$GOMAXPROCS个Goroutine在同时运行
   - P何时创建: 在确定了P的最大数量N后，运行时系统会根据这个数量创建N个P
2. M的数量
   1. go语言本身的限制
      - go程序启动时，会设置M的最大数量(线程数限制)，默认 10000
      - 但是内核很难支持这么多的线程数，所以这个限制可以忽略
   2. 一个M阻塞了，会创建新的M
   3. M何时创建: 没有足够的M来关联P并运行其中的可执行的G(比如,所有的M此时都阻塞住了，而P中还有很多就绪任务，就会去寻找空闲的M，而没有空闲的，就会去创建新的M)
3. G的数量
   1. 一个G的大小约2~4K的内存，注意该内存必须是连续的内存块
   2. G的个数没有限制，但是理论上会受到内存的影响
   3. P 的数量基本是受本机的核数影响，但是P的数量会不会影响G的数量的创建？
      - 不影响。且G多了少了，P也该干嘛干嘛，不会带来灾难性的问题
   4. Goroutine数量怎么预算，才叫合理？

总结: 

1. M: 有限制，默认数量限制是 10000，可调整。
2. G: 没限制，但受内存影响。
3. P: 受本机的核数影响，可大可小，不影响 G 的数量创建。

在真实的应用场景中，没法如此简单的定义。如果你 Goroutine: 

1. 在频繁请求 HTTP，MySQL，打开文件等，那假设短时间内有几十万个协程在跑，那肯定就不大合理了（可能会导致  too many files open）。
2. 常见的 Goroutine 泄露所导致的 CPU、Memory 上涨等，还是得看你的 Goroutine 里具体在跑什么东西。

---

# 2.信道channel

## 2.1.概述channel

1. 应用场景
   1. 协程间通信
   2. 并发函数间的同步 
   3. select
   4. 超时的channel
   5. 延迟执行某个方法
   6. Timer/Ticker
2. 分类
   1. 有缓冲
   2. 无缓冲
      - ch := make(chan int, 100)
3. 注意细节
   1. 在多个goroutine从/往一个channel中receive/send数据，不必考虑额外的同步措施
   2. 关闭channel
      1. 关闭channel时，会把recvq/sendq中的G全部唤醒
      2. 向关闭的channel中读/写
         1. 往一个被close的channel中发送数据 ==> panic
         2. 从一个被close的channel中接收数据 ==> 不会被阻塞，而是立即返回，接收完已发送的数据后会返回元素类型的零值(zero value)。
   3. 从一个nil channel中接收数据 ==> 会一直被block
4. 与锁对比
   - 默认情况下，发送和接收会一直阻塞着，直到另一方准备好。这种方式可以用来在gororutine中进行同步，而不必使用显示的锁或者条件变量。
5. channel和共享内存有什么优劣势
   1. 共享内存粒度大，消耗大。一般用于线程/进程通信
   2. channel粒度小，用于协程同步
6. channel使用时panic的场景
   1. 关闭值为nil的channel
   2. 关闭已经被关闭的channel
   3. 向已经关闭的channel写数据

## 2.2.[channel原理](https://my.oschina.net/renhc/blog/2246871)

```go
type hchan struct {
      /* 环形缓冲区相关 */
      qcount   uint           // 环形缓冲区size，当前元素个数
      dataqsiz uint           // 环形缓冲区capacity，make(chan T,N) 中的N
      sendx    uint           // 环形缓冲区w_idx
      recvx    uint           // 环形缓冲区r_idx
      buf      unsafe.Pointer // 指向环形缓冲区
      closed   uint32         // 标识当前通道是否处于关闭状态
      /* 保存元素相关 */
      elemsize uint16         // 每个元素的大小
      elemtype *_type         // element type元素类型，用于数据传递过程中的赋值
      /* 协程队列 */
      recvq    waitq          // 等待读消息的goroutine队列
      sendq    waitq          // 等待写消息的goroutine队列
      /* 同步锁 */
      lock mutex              // 互斥锁，为每个读写操作锁定通道(发送和接受是互斥的)
}

// sudog 代表goroutine
type waitq struct {
      first *sudog
      last  *sudog
}
```

- lock \=\=> recvq/sendq能否获取goroutine？ \=\=> 判断环形缓冲区buf是否可读可写？\=\=>unlock

1. send过程
   1. 获取channel的mutex
   2. 判断recvq队列中是否有goroutine
      1. 有goroutine
         1. 获取一个goroutine，然后将元素直接写入goroutine
         2. 写入后唤醒goroutine
      2. 没有goroutine
         1. 查看环形缓冲区buf是否满了
            1. 不满 ==> 写入数据到buf
            2. 满了 ==> 等待goroutine加入sendq，等待被唤醒(被唤醒时，数据已经被取走)
   3. 结束
2. recv过程

## 2.3.高级使用场景

### 2.3.1.select监控多个channel

使用select可以监控多个channel，比如监控多个channel，当其中有一个channel有数据是，select就会立刻返回

```go
func addNumberToChan(chanName chan int) {
    for {
        chanName <- 1 // 向chan写入数据
        time.Sleep(1 * time.Second)
    }
}

func main() {
    var chan1 = make(chan int, 10)
    var chan2 = make(chan int, 10)

    go addNumberToChan(chan1)
    go addNumberToChan(chan2)

    for {
        select {
        case e := <- chan1: // 从chan读取数据
            fmt.Printf("Get element from chan1: %d\n", e)
        case e := <- chan2: // 从chan读取数据
            fmt.Printf("Get element from chan2: %d\n", e)
        default:
            fmt.Printf("No element in chan1 and chan2.\n")
            time.Sleep(1 * time.Second)
        }
    }
}
```

### 2.3.2.超时channe

希望从一个管道中读取数据，在管道中没有数据时，我们不想让程序永远阻塞在管道中，而是设定一个超时时间，在此时间段中如果管道中还是没有数据到来，则判定为超时

```go
// WaitChannel作用就是检测指定的管道conn中，是否有数据到来
// 通过select语句轮询conn、timer.C两个管道，timer会在1s后向timer.C写入数据，如果1s内conn还没有数据，则会判断为超时
func WaitChannel(conn <-chan string) bool {
    timer := time.NewTimer(1 * time.Second)
 
    select {
    case <- conn:
        timer.Stop()
        return true
    case <- timer.C: // 超时
        println("WaitChannel timeout!")
        return false
    }
}
```

### 2.3.3.延迟执行某个方法

有时我们希望某个方法在今后的某个时刻执行，如下代码所示: 
```go
func DelayFunction() {
    timer := time.NewTimer(5 * time.Second)
 
    select {
    case <- timer.C:
        log.Println("Delayed 5s, start to do something.")
    }
}
```

### 2.3.4.Timer/Ticker

---

# 3.context包

1. Context的使用场景，一句话概括: 控制goroutine的生命周期
   - 当一个计算任务被goroutine承接了之后，由于某种原因（超时，或者强制退出）我们希望中止这个goroutine的计算任务，那么就用得到这个Context了
2. 实际使用场景
   1. RPC调用: context.WithCancel、cancel()
   2. 超时请求: context.WithTimeout
   3. HTTP服务器的request互相传递数据: WithVal
   4. pipeline流水线模型
      1. 其实pipeline模型的实现和Context并无关系，没有context我们也能用chan实现pipeline模型
      2. 但是对于整条流水线的控制，则是需要使用上Context的
3. 分类
   1. CancelContext
   2. TimeoutContext
   3. DeadLineContext
   4. ValueContext

--- 

# 3.锁

## 3.1.sync.Mutex

对比于 Spinlock 的忙等待，如果 Mutex 未获得锁，会释放对 CPU 的占用

注意: Go里的互斥锁，是不可重入锁

## 3.2.原子操作

原子操作是需要硬件支持的

### 3.3.CAS

```go
func atomicAdd(p *int32, incr int32) int32 {
   for {
      oldValue := *p    
      newValue := oldValue + incr    
      if atomic.CompareAndSwapInt32(p, oldValue, newValue){      return newValue    
      }  
   }
}
```

Go 语言 atomic.AddInt32 的实现是直接使用汇编 LOCK XADDL 完成的，不是基于 CAS 和循环

### 3.4.自旋锁

下面就是经典的自旋锁 —— 通过反复检测锁变量是否可用来完成加锁。在加锁过程中 CPU 是在忙等待，因此仅适用于阻塞较短时间的场合；其优势在于避免了线程切换的开销

```go
type spinLock int32func (p *spinLock) Lock() {  
   for !atomic.CompareAndSwapInt32((*int32)(p), 0, 1) {  }
}
func (p *spinLock) Unlock() {  
   atomic.StoreInt32((*int32)(p), 0)
}
```

## 3.5.sync包

## 3.5.1.RWMutex 读写锁

读写锁，通过将资源的访问者分成读者和写者，允许多个读者同时访问资源，从而提高共享资源的并发度。适用于读远多于写的场景。

## 3.5.2.WaitGroup

用于对 goroutine 的并发控制
1. 在主 goroutine 里使用 Add(n) 指定并发数量，并使用 Wait() 等待
2. 所有任务都调用 Done() (配合 defer 使用效果更佳)

使用时注意的坑
1. 作为参数传递时，需要传递指针
   1. [案例1](https://blog.csdn.net/yzf279533105/article/details/97041564)
   2. [案例2](https://www.jb51.net/article/99199.html]
2. Done次数 > Add次数 ==> panic

## 3.5.3.Pool 对象池

对象池，用于缓存后续会用到的对象，从而缓解 gc 压力。例如 fmt 包用它来缓存输出缓冲区。

## 3.5.4.Once [单例](https://blog.csdn.net/LinHenk/article/details/91047863)

“单例”: once.Do(f) 保证 f 只会被执行一次。f 被执行后，通过原子操作保证了性能。


使用案例

```go
func main() {
	once := sync.Once{}
	for i := 0; i < 5; i++ {
		once.Do(doSomething)
		time.Sleep(time.Second)
	}
	fmt.Println("end")
}
func doSomething() {
	fmt.Printf("do it, time_stamp:%d\n", time.Now().Unix())
}
// 执行结果
//    do it, time_stamp:1559812858
//    end
```

源码分析: 互斥锁、atomic

```go
type Once struct {
	m    Mutex  //互斥锁
	done uint32 //f方法的执行标识，0未执行，1已执行
}

func (o *Once) Do(f func()) {
 	//done==1，表示f已经被执行了，直接返回
	if atomic.LoadUint32(&o.done) == 1 {
		return
	}
	
	//加锁
	o.m.Lock()
	//使用defer释放锁
	defer o.m.Unlock()
	
	//再次判断done是否已经执行，done==0表示未执行，双重校验，避免f多次执行
	if o.done == 0 {
		//执行f方法，执行完成后，done置为1，
		//因为使用defer将done置为1，所以即便是f中panic了，done也会被置为1
		defer atomic.StoreUint32(&o.done, 1)
		f()
	}
}
```

## 3.5.5.Cond 条件同步

- Wait(): 阻塞当前的 goroutine，等待唤起
- Signal(): 唤起一个阻塞的 goroutine
- Broadcast(): 唤起所有阻塞的 goroutine

## 3.5.6.Map [并发的map](https://www.cnblogs.com/jiujuan/p/13365901.html)

通过 Load、Store、LoadOrStore、Delete、Range 等方法提供线程安全的 map 数据结构

1. 原理
   - 是通过"分离读写map"和"原子指令"来实现读的近似无锁，并通过"延迟更新"的方式来保证读的无锁化。一般情况下可以替换上面2种锁。
2. 看看 sync.map 优点
   1. 空间换时间: 通过冗余的两个数据结构(read、dirty)，实现加锁对性能的影响。
   2. 使用只读数据(read)，避免读写冲突。
   3. 动态调整，miss次数多了之后，将dirty数据迁移到read中。
   4. double-checking
   5. 延迟删除。 删除一个键值只是打标记，只有在迁移dirty数据的时候才清理删除的数据。
   6. 优先从read读取、更新、删除，因为对read的读取不需要锁。
3. 名字概念
   1. onlyRead atomic.Value: 只读
   2. dirty: 写

```go
type Map struct {
    // 当涉及到脏数据(dirty)操作时候，需要使用这个锁
    mu Mutex
    
    // read是一个只读数据结构，包含一个map结构，
    // 读不需要加锁，只需要通过 atomic 加载最新的指正即可
    read atomic.Value // readOnly
    
    // dirty 包含部分map的键值对，如果操作需要mutex获取锁
    // 最后dirty中的元素会被全部提升到read里的map去
    dirty map[interface{}]*entry
    
    // misses是一个计数器，用于记录read中没有的数据而在dirty中有的数据的数量。
    // 也就是说如果read不包含这个数据，会从dirty中读取，并misses+1
    // 当misses的数量等于dirty的长度，就会将dirty中的数据迁移到read中
    misses int
}
// 只读map，对该map的访问不需要加锁
// 但是这个map也不会增加元素，元素会被先增加到dirty中，然后后续会迁移到read只读map中，通过原子操作所以不需要加锁操作
type readOnly struct {
    // m包含所有只读数据，不会进行任何的数据增加和删除操作 
    // 但是可以修改entry的指针因为这个不会导致map的元素移动
    m       map[interface{}]*entry
    
    // 标志位，如果为true则表明当前read只读map的数据不完整，dirty map中包含部分数据
    amended bool // true if the dirty map contains some key not in m.
}
```

1. 查找: 根据key，查找val。函数为load()
   - 从函数可以看出，如果查询的键值正好在m.read中，不需要加锁，直接返回结果，优化了性能。
   - 即使不在read中，经过几次miss后， m.dirty中的数据也会迁移到m.read中，这时又可以从read中查找。
所以对于更新／增加较少，加载存在的key很多的case，性能基本和无锁的map类似
      ```go
      func (m *Map) Load(key interface{}) (value interface{}, ok bool) {
          // 首先从只读ready的map中查找，这时不需要加锁
          read, _ := m.read.Load().(readOnly)
          e, ok := read.m[key]
          // 如果没有找到，并且read.amended为true，说明dirty中有新数据，从dirty中查找，开始加锁了
          if !ok && read.amended {
            m.mu.Lock() // 加锁
            // 又在 readonly 中检查一遍，因为在加锁的时候 dirty 的数据可能已经迁移到了read中
            read, _ = m.read.Load().(readOnly)
            e, ok = read.m[key]
            // read 还没有找到，并且dirty中有数据
            if !ok && read.amended {
                  e, ok = m.dirty[key] //从 dirty 中查找数据
                  // 不管m.dirty中存不存在，都将misses + 1
                  // missLocked() 中满足条件后就会把m.dirty中数据迁移到m.read中
                  m.missLocked()
            }
            m.mu.Unlock()
          }
          if !ok {
            return nil, false
          }
          return e.load()
      }
      ```
   - missLockerd() 迁移数据
      ```go
      func (m *Map) missLocked() {
        m.misses++
        if m.misses < len(m.dirty) {//misses次数小于 dirty的长度，就不迁移数据，直接返回
            return
        }
        m.read.Store(readOnly{m: m.dirty}) //开始迁移数据
        m.dirty = nil   //迁移完dirty就赋值为nil
        m.misses = 0  //迁移完 misses归0
      }
      ```
2. 新增和更新
   - 操作都是先从m.read开始，不满足条件再加锁，然后操作m.dirty
        ```go
        // Store sets the value for a key.
        func (m *Map) Store(key, value interface{}) {
          // 直接在read中查找值，找到了，就尝试 tryStore() 更新值
          read, _ := m.read.Load().(readOnly)
          if e, ok := read.m[key]; ok && e.tryStore(&value) {
              return
          }
          // m.read 中不存在
          m.mu.Lock()
          read, _ = m.read.Load().(readOnly)
          if e, ok := read.m[key]; ok {
              if e.unexpungeLocked() { // 未被标记成删除，前面讲到entry数据结构时，里面的p值有3种。1.nil 2.expunged，这个值含义有点复杂，可以看看前面entry数据结构 3.正常值
                    m.dirty[key] = e // 加入到dirty里
              }
              e.storeLocked(&value) // 更新值
          } else if e, ok := m.dirty[key]; ok { // 存在于 dirty 中，直接更新
              e.storeLocked(&value)
          } else { // 新的值
              if !read.amended { // m.dirty 中没有新数据，增加到 m.dirty 中
                    // We're adding the first new key to the dirty map.
                    // Make sure it is allocated and mark the read-only map as incomplete.
                    m.dirtyLocked() // 从 m.read中复制未删除的数据
                    m.read.Store(readOnly{m: read.m, amended: true}) 
              }
              m.dirty[key] = newEntry(value) //将这个entry加入到m.dirty中
          }
          m.mu.Unlock()
        }
        ```
3. 删除
   - 还有更好的方法没？java里面有一个分段锁，保证在操作不同 map 段的时候， 可以并发执行， 操作同段 map 的时候，进行锁的竞争和等待。从而达到线程安全， 且效率大于 synchronized。而不是直接加一把大锁，锁住整个map
      ```go
      // Delete deletes the value for a key.
      func (m *Map) Delete(key interface{}) {
         // 从 m.read 中开始查找
         read, _ := m.read.Load().(readOnly)
         e, ok := read.m[key]
         
         if !ok && read.amended { // m.read中没有找到，并且可能存在于m.dirty中，加锁查找
            m.mu.Lock() // 加锁
            read, _ = m.read.Load().(readOnly) // 再在m.read中查找一次
            e, ok = read.m[key]
            if !ok && read.amended { //m.read中又没找到，amended标志位true，说明在m.dirty中
                  delete(m.dirty, key) // 删除
            }
            m.mu.Unlock()
         }
         if ok { // 在 m.ready 中就直接删除
            e.delete()
         }
      }
      ```


## 3.5.7.atomic

- Load: 从相应的内存地址中获取对应的值
- Store: 将对应的值保存在相应的内存地址中
- Add: 该类方法可以理解是Load和Store的结合，也就是先Load然后Add
- Swap: 该类方法可以理解为先Load，在Store新值，然后返回旧值
- CompareAndSwap: 该类方法可以这样理解: 先比较旧数据和地址中保存数据的值，如果相同的话，执行Swap，把新的数值保存在地址中，返回true，如果不同，那么直接返回false


---

# 4.GC

## 4.1.常用GC方法

1. 引用计数
   1. 优点: 简单
   2. 缺点
      1. 需要额外空间记录计数
      2. 无法处理循环引用，如a.b=b; b.a=a
      3. 频繁更新引用计数降低性能
2. 标记清除
   1. 缺点
      1. STW(stop the world)，让程序暂停，程序出现卡顿
      2. 标记需要扫描整个heap
      3. 清除数据会产生heap碎片
3. 复制收集
4. 分代收集
5. 三色标记法
   1. 黑: 不回收
   2. 灰: 中间状态，待遍历
   3. 白: 垃圾

go的GC策略: [三色标记算法+GC混合写屏障](https://www.bilibili.com/video/BV1wz4y1y7Kd?from=search&seid=3823789319774370173&spm_id_from=333.337.0.0)

三色标记法

1. 初始时，所有的对象都标记为白色
2. 从根出发扫描所有可达对象，标记为灰色，放入灰色队列
3. 从灰色队列取出灰色对象，①将其引用对象标记为灰色，放入灰色队列，②自身标记为黑色，放入黑色队列
4. 重复3，直到灰色对象队列为空。此时，黑色是有效数据；白色对象即为垃圾，进行回收

存在问题: 不启动STW(stop the world)，在并发场景下，“在同一个时刻，若同时满足以下两个条件时”，会导致白色对象丢失

1. “灰色对象不再引用之前的白色对象A”
2. “白色对象A被黑色对象引用时”，白色对象会被GC回收掉

启动STW，可以解决并发问题，但是会导致性能低下。 ==> 之前已经知道了，当且仅当在上述2个条件同时满足时，才会导致GC回收掉有效的数据。那么，只要破坏了上述2个条件中的一个，就可以解决该问题。有两种解决方案，

1. “强”三色不变式
   - 破坏条件2: 强制性地不允许黑色对象引用白色对象
2. “弱”三色不变式
   - 允许黑色对象可以引用白色对象，但是该白色对象必须被其他黑色对象直接或间接引用 

如何实现上述的“强”/“弱”三色不变式？ ==> [屏障(HOOK/handler)](https://www.bilibili.com/video/BV1wz4y1y7Kd?p=7)

1. 插入屏障: 对象被引用时，触发的机制
   1. // todo
2. 删除屏障: 对象被删除时，触发的机制
   1. // todo



---


# 4.常见数据结构

## 4.1.init()
1. 使用场景
   1. 变量初始化
   2. 检查/修复程序的状态
   3. 注册
   4. 运行一次计算
2. 执行时机: 引入包时，执行。(即使包被导入多次，初始化只需要一次)
1. 执行顺序: const、var、init
4. 假设包引入关系: pkg1\=\=>pkg2\=\=>pkg3，有多个init，执行顺序是？
      - 与函数调用栈一样，后进先出: pkg3的init、pkg2的init、pkg1的init


## 4.2.struct能不能比较

- 相同类型的struct能比较
- 不同类型的struct不能比较


## 4.3.go深拷贝，什么时候需要深拷贝

本质: 拷贝的是数据？还是数据地址？

## 4.4.defer / recover / panic

### 4.4.1.defer应用场景

defer的使用十分频繁

1. 释放资源: DB连接
2. defer unlock()
3. recover仅仅在defer中有效

### 4.4.2.[recover防止程序崩溃](http://c.biancheng.net/view/64.html)

1. recover是go语言的内建函数，可以让进入宕机或panic的Go恢复过来
2. recover仅仅在延迟函数defer中有效

panic 和 recover 的组合有如下特性

1. 有 panic 没 recover，程序宕机
2. 有 panic 也有 recover，程序不会宕机，执行完对应的 defer 后，从宕机点退出当前函数后继续执行。


```go
package main
import (
	"fmt"
	"runtime"
)
func ProtectRun(cbk func()) {
	defer func() {
		err := recover()
		switch err.(type) {
		case runtime.Error:
			fmt.Println("runtime error:", err)
		default:
			fmt.Println("error:", err)
		}
	}()
	cbk()
}
func manualPanic() {
	panic("手动崩溃")
}
func runtimePanic() {
	var a *int
	*a = 1
}
func main() {
	fmt.Println("BEGIN")
	ProtectRun(manualPanic)
	ProtectRun(runtimePanic)
	fmt.Println("END")
}
// BEGIN
// error: 手动崩溃
// runtime error: runtime error: invalid memory address or nil pointer dereference
// END
```


## 4.5.[内存逃逸](https://zhuanlan.zhihu.com/p/145468000)

1. 知道go的内存逃逸么？
   - golang程序变量会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在栈上分配。否则就说它 逃逸 了，必须在堆上分配
2. 什么情况下会发生内存逃逸？即: 能引起变量逃逸到“堆”上的典型情况
   1. 在函数中把局部变量返回
      - 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出
   2. 在一个slice切片上存储指针或带指针的值。一个典型的例子，即[]\*string
      - 这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上
   3. slice的背后数组被重新分配了，因为append时可能会超出其容量(cap)
      - slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
   4. 在 interface 类型上调用方法
      - 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配
   5. 发送指针或带有指针的值到channel中
      - 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放

## 4.6.slice/array

slice动态数组: buf / cap / size

- 内存逃逸
  1. 内存扩充时
     - 底层数组扩展时，会生成一个新的底层数组。所以旧底层数组仍然会被旧slice引用，新slice和旧slice不再共享同一个底层数组
  2. slice中存放的元素是指针

## 4.7.[map](https://blog.csdn.net/fengshenyun/article/details/100582679)

1. 名词解释
   1. 哈希桶: 整个哈希数组，数组内的每个元素就是一个桶
   2. 桶链: 哈希桶的每个桶以及该桶下面挂着的所有的溢出桶
   3. 桶bucket: 一个bmap结构，与溢出桶的区别在于它是哈希桶数组上的一个元素
   4. 溢出桶: 一个bmap结构，与桶区别是，它不是哈希桶数组的元素，而是挂在哈希桶数组上或挂在其它溢出桶上
   5. 负载因子 = 元素个数 / len(哈希桶数组)
2. 查找过程
   - 可以简单理解为：hash函数从“哈希桶”上找到桶 ==> 从桶的桶链(桶+溢出桶)上找到key
3. 插入过程
   1. 常规插入: hash函数从“哈希桶”上找到桶 ==> 若桶满了 ==> 在桶下面挂一个溢出桶 ==> 插入元素到溢出桶
   2. 扩容
      1. 负载因子\>6.5 ==> 2倍扩容
      2. 负载因子\<6.5 && 溢出桶个数过多 ==> 等量扩容

```go
/* 当map做为传参时，实际传入的是一个hmap指针 */
type hmap struct {
	count     int     // 记录map当前元素个数   
	flags     uint8   // 读、写、扩容、迭代等标记，用于记录map当前状态
	B         uint8   // 用于计算桶大小， bucketSize = 1 << B
	noverflow uint16  // 溢出桶个数，当溢出桶个数过多时，这个值是一个近似值
	hash0     uint32  //

	buckets    unsafe.Pointer // 当前哈希桶首地址
	oldbuckets unsafe.Pointer // 旧哈希桶首地址
	nevacuate  uintptr        // 已迁移哈希桶个数

	extra *mapextra           //
}
/* bmap 描述一个桶，既可以是哈希桶也可以是溢出桶 */
type bmap struct {
	tophash   [bucketCnt]uint8     // 一个长度为8的数据，会存放key的hash值的高8位，用于后续快速查找桶内元素
	keys      [bucketCnt]KeyType   // key/value存储的地方
	values    [bucketCnt]ValueType
	overflow  *bmap                // 指向下一个溢出桶
}
```



---

# 5.场景/设计

## 5.1.[那如何实现一个timeout的锁？](https://www.jianshu.com/p/4d85661fba0a?utm_campaign=shakespeare)

// todo

## 5.2.单元测试 

如果一个包要依赖另一个包，这个时候如何写单元测试

## 5.3.连接池实现

// todo

## 5.4.[用go实现一个协程池，大概用什么实现](https://studygolang.com/articles/15477)

```go
type Task struct {
	f func() error //一个无参的函数类型
}
type Pool struct {
	EntryChannel chan *Task //对外接收Task的入口
	worker_num   int        //协程池最大worker数量,限定Goroutine的个数
	JobsChannel  chan *Task //协程池内部的任务就绪队列
}
```

## 5.5.cgo了解过引入的风险点吗？

1. Go中调用C一共有两种办法
   1. 第一种是将C代码直接嵌入到GO源文件中
   2. 第二种是将C代码写在C文件中，再在GO文件中引入
2. [cgo使用方法](https://blog.csdn.net/oyoung_2012/article/details/108326504)

## 5.6.[go实现不重启热部署](http://www.zzvips.com/article/67043.html)

## 5.7.性能分析工具 pprof

- 线上问题一般怎么排查，比如oom
