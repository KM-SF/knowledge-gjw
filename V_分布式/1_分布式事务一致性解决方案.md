# 分布式事务

- 网络是产生分布式事务的根本原因

# 1. 基础概念

## 1.1. 什么是事务

在计算机系统中，更多的是通过关系型数据库来控制事务，之前已经讲过SQL数据库，它具有ACID特性。在此不再详述。

## 1.1. 本地事务

事务的运行在本地的单机环境下，不需要跨网络执行

## 1.2. 分布式事务

### 1.2.1. 分布式事务产生的背景

① 单机系统中，访问多个数据库实例（单服务访问多个数据库实例）

“用户数据库”、“订单数据库”分别存储在两个MySQL数据库中，用户管理系统删除用户信息，需要删除用户订单信息，由于数据分布在不同的数据实例，需要通过不用的数据库连接去操作数据，此时产生分布式事务。

② 多服务访问同一个数据库实例

③ 典型的场景就是微服务架构：微服务架构中通过远程调用RPC完成事务

先介绍下**微服务**：随着业务的不断扩展，为了保证系统的可扩展性，通常会将单体系统转换为多机的微服务架构，即把每个模块都拆解/模块化，形成一个个的服务。这样的一个个服务模块一般部署在不同的机器上，服务与服务之间采用<u>网络远程协作</u>配合完成工作。

再介绍**分布式事务**：即分布式系统环境下，由不同的服务之间通过网络协作完成的事务。

### 1.2.2. 分布式事务数据不一致问题

通过对比分布式事务/本机事务，说明分布式事务数据不一致问题的原因。

```c
begin transaction
    // 1. 本地数据库操作：张三减少金额
    // 2. 本地数据库操作：李四增加金额
end transaction
```

```c
begin transaction
    // 1. 本地数据库操作：张三减少金额
    // 2. 远程调用：李四增加金额
end transaction
```

分析：本地事务，通过数据库提供的事务，就可以保证安全；分布式事务，当执行完步骤1后，再执行远程调用让李四增加金额成功了，<u>可能会由于网络原因</u>，远程调用没返回，此时本地事务提交失败就回滚了张三减少金额的操作，最终造成李四（远端）和张三（本地）数据不一致了。

因此，在分布式系统中，传统的事务就失效了/无法使用了，它是由于网络问题导致的。

# 2. 分布式事务基础理论CAP

场景：分布式云存储，存在master/slaver节点，数据会写入主节点、从从节点读取数据，实现读写分离。从数据库要不断的将数据同步到和主数据库保持一致，以致于用户读到的数据是正确的。

## 2.1. CAP理论

CAP：Consistency、Availability、Partition tolerance，分别表示（一致性、可用性、分区容忍性）。

C：一致性，所有客户端看到都是同一份数据，即使在数据更新和删除之后

A：可用性，即使部分节点发生故障，所有客户端也能找到可用的数据备份

P：分区容忍性，即使发生网络分区故障，系统仍然能够按照预期正常工作

CAP定理在分布式领域至关重要，在构建大型分布式系统的时候我们必须根据自己业务的独特性在三者之间进行权衡。由于网络的各种不确定因素，在构建分布式应用的时候我们往往不得不考虑分区容忍性，这个时候我们通常只能在一致性和可用性之间进行选择

> 强一致性
>
> > 系统中的某个数据被成功更新后，后续任何对该数据的读取操作都将得到更新后的值；
>
> 弱一致性
>
> > 系统中的某个数据被更新后，后续对该数据的读取操作可能得到更新后的值，也可能是更改前的值。但经过“不一致时间窗口”这段时间后，后续对该数据的读取都是更新后的值
> >
> > 注：最终一致性就是弱一致性的一种

## 2.2. BASE理论

上面提到，实现6个9的思路，引出了概念“强一致性”、“最终一致性”。

<u>再谈CAP，在满足P的前提下，C和A存在矛盾性</u>：① CAP的强一致性要求，在任何时刻，查询每个节点的数据都是一致的。但是这样会导致，如果存在10个节点，当前1个节点死掉，为了保证数据强一致性，那么另外的9个节点则不能提供服务，系统就不可用了！这显然是不符合系统设计要求的。② 但是，如果不保证数据一致性，那么，错误的数据一定是不可容忍的，即：我们存了100w，别人给少存了，那谁都会不开心。

### 2.2.1. 最终一致性

允许在某个时间内，每个节点的数据不一致，但是经过一段时间后，每个节点的数据必须达到一致，这就是最终数据一致性。

### 2.2.2. BASE

BASE：Basically Available（基本可用）、Soft state（软状态）、Eventually consistent（最终一致性）。

*<u>基本可用</u>*：`分布式系统故障时，允许损失部分功能，保证核心功能可用`。如，电商网站交易付款出现问题了，商品仍然可以正常浏览。

<u>*软状态*</u>：如，微信支付时，先经过“支付中状态”、“数据同步中状态”，待数据最终一致后，状态改为“支付成功”或“支付失败”。

<u>*最终一致性*</u>：经过一段时间后，所有节点数据都达成一致。如，微信支付，支付状态会最终变为“支付成功”或“支付失败”中的某一个。

BASE理论是对CAP中AP的扩展，通过*<u>牺牲强一致性来获取高可用性</u>*。当出现故障时，允许部分不可用，但是要保证核心功能可用，允许数据在一段时间内是不一致的，但是最终会达到一致性状态。

---

# 3. 分布式事务一致性解决方案


## 3.1.（两阶段提交） 2PC 

2PC是强一致性方案，即舍A保C的CP模型，通过牺牲可用性来保证一致性，这种方法适用于对一致性要求高的场景。比如，金融交易等

- 应用场景：数据库XA协议、Seata

### 3.1.1. 原理

2PC，顾名思义：将整个事务分成2个阶段，准备阶段（Prepare）、提交阶段（Commit）。它包含两个身份：事务协调者（事务管理者）、参与者（事务执行者）

1. *<u>准备阶段</u>*
   1. 协调者向每个参与者发送Prepare消息
   2. 每个数据库参与者在本地执行事务（`此时锁定资源`），并写本地的Undo/Redo日志，此时事务没有提交
2. <u>*提交阶段*</u>
   1. （提交/回滚阶段）协调者收到参与者执行失败/成功时，根据情况（**所有成功才成功，一个失败就失败**），向每个参与者发送（回滚/提交）消息。
   2. 参与者根据协调者发送的指令，执行操作，执行回滚/提交后，`释放锁资源`(注意：必须在最后截断释放锁资源）。

### 3.1.2. 缺陷

1. **协调者单点故障问题**：协调者在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦协调者宕机，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。
1. **同步阻塞问题**：执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。也就是说从投票阶段到提交阶段完成这段时间，资源是被锁住的。
2. **数据一致性问题**
   - 如果协调者发送commit给所有参与者，由于网络原因，若部分参与者收到commit，部分参与者没收到commit，就会导致数据不一致

## 3.2. （三阶段提交）3PC

### 3.2.1. 背景

为了解决两段式提交的『单点故障问题、同步塞问题和数据一致性问题』，“三段式提交”（3 Phase Commit，3PC）协议出现了

与两阶段提交不同的是，三阶段提交有两个改动点。
1. 引入超时机制: 同时在协调者和参与者中都引入超时机制
2. 把原本的2PC的准备阶段再细分为两个阶段: 将准备阶段一分为二的理由是，这个阶段是重负载的操作，一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，这时候涉及的数据资源都会被锁住。如果此时某一个参与者无法完成提交，相当于所有的参与者都做了一轮无用功。所以，增加一轮询问阶段，如果都得到了正面的响应，那事务能够成功提交的把握就比较大了，也意味着因某个参与者提交时发生崩溃而导致全部回滚的风险相对变小了。

### 3.2.2. 原理

1. CanCommit阶段：询问
   - 协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应
2. PreCommit阶段：根据询问结果，执行事务开启/中断
    1. 执行事务
        - 协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的`预执行`
    2. 中断事务
        1. 协调者等待超时，依然没有接到参与者的响应，那么就执行事务的`中断`
        2. 有任何一个参与者向协调者发送了No响应或者等待超时之后，那么就执行事务的`中断`
3. 第三阶段：doCommit阶段
    1. 提交事务
        - 协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的`commit`
          - 注意：如果参与者因为网络原因收不到commit时，会执行commit操作（因为之前经过CanCommit阶段进行了询问，所以，事件大概率会成功）
    2. 回滚事务
        1. 协调者等待超时，依然没有接到参与者的响应，那么就执行事务的`中断`
        2. 有任何一个参与者向协调者发送了No响应或者等待超时之后，那么就执行事务的`中断`

### 3.2.3. 分析

1. 解决了2PC单点故障，并减少阻塞：在第三阶段，一旦参与者无法及时收到来自协调者的消息后，参与者不会一直阻塞等待，它会默认执行commit（因为之前已经经过CanCommit阶段进行了询问事务是否能执行成功，所以，事件大概率会成功）
2. 仍然存在一致性问题：在第三阶段，当协调者向参与者发送了中断事务的命令，而此时网络发生了故障，部分参与者收到了中断事务的命令，部分参与者未收到（因为参与者超时会默认执行commit），这就导致了事务不一致


## 3.3. TCC（Try+Confirm+Cancle）

TCC本质上是应用层面的2PC，TCC又称之为两阶段补偿型。是一种业务侵入性很强的事务方案，要求业务处理过程必须拆分为“预留业务资源”和“确认/释放消费资源”两个子过程。


1. Try—尝试执行阶段
   1. 完成所有业务可执行检查（保障一致性）
   2. 预留好事务需要用到的所有业务资源（保障隔离性）
2. Confirm—确认执行阶段
   - 不进行任何业务检查，直接使用try阶段准备的资源来完成业务处理。注意，Confirm 阶段可能会重复执行，因此需要满足幂等性
3. Cancle—取消执行阶段
   - 释放Try阶段预留的业务资源。注意，Cancel 阶段也可能会重复执行，因此也需要满足幂等性。

[举例] TCC是基于BASE理论的类2PC方案，根据业务的特性对2PC的流程进行了优化。下面来看一个简化版的订销存交易流程：APP --> 订单服务 --> 库存服务 --> 积分服务
1. 分析
   1. 用户在电商网站下订单后通知库存服务扣减库存，最后通过积分服务给用户增加积分。整个交易操作应该具有原子性，这些交易步骤要么一起成功，要么一起失败，必须是一个整体性的事务。
   2. 假设用户下完订单通知库存服务扣减库存失败时，比如原本是10件商品卖了1件剩余9件，但由于库存DB操作失败，导致库存还是10件，这时就出现了数据不一致的情况，此时如果有其它用户也进行了购买操作，则可能出现超卖的问题。
   3. 如果采用2PC的解决方案，在整个交易成功完成或者失败回滚之前，其它用户的操作将会处于阻塞等待的状态，这会大大的降低系统的性能和用户体验。
2. 2PC和TCC对比
    - TCC的操作也分为两个阶段，Try（尝试）阶段和Confirm/Cancel（确认/取消）阶段，不同于2PC第一阶段的Prepare，TCC在Try阶段主要是对资源的预留操作这类的轻量级操作，比如**冻结部分库存数量**，它不需要像2PC在第二阶段完成之后才释放整个资源，也就是它不需要等待整个事务完成后才进行提交，这时其它用户的购买操作可以继续正常进行，因此它的阻塞范围小时间短暂，性能上比2PC方案要有很大的提升
    - TCC相对2PC协议的XA方案更轻量级，但它要求所有的事务参与方都必须要提供三个操作接口：Try/Confirm/Cancel。因此各个微服务接通在接入时会有一定的成本，而且这对一些难以改动的老旧系统来说甚至是不可行的


- TCC要注意3种异常处理
  1. 空回滚：没有调用try，但调用了cancle（解决：try执行后，添加日志；cancle执行前，查看是否有日志，来决定是否执行cancle）
  2. 幂等：同一语句，无论执行多少次，结果都相同（解决：增加执行标记，每次执行前都查询标记，若标记存在，则不再执行）
  3. 悬挂：cancle比try先执行，即，try超时，TM通知执行cancle之后，try之后却预留资源成功，导致这份资源没人使用。（解决：若第2阶段执行完，则第1阶段不再继续执行）



--- 

基于2PC的强一致性方案的阻塞特性对性能的影响很大，在CAP定理中属于CP范畴。在互联网应用中为了提升性能和可用性，基于BASE理论，可以使用最终一致性来替代强一致性，通过牺牲部分一致性来换取性能和可用性的提升


### 3.4. 本地事务状态表

1. 本地事务状态表
2. “定时器”扫描本地事务状态表

举例说明，假设，有分布式事务包含3个子事务，分别是：A，B，C，假设本地事务记录的状态依次是A，B，C

1. 在本地创建一个“本地消息表”，保存每一组分布式事务的状态
2. 在一组分布式事务A，B，C执行之前，先插入一条记录到本地消息表，状态设置为A
3. 执行事务A，成功后，修改状态为B，由定时器扫描本地事务状态表，执行事务B，...，一次执行，直到三个事务都执行完毕

补充：事务执行失败的处理方式

1. 某一步执行失败，会在表中记录失败的状态
2. 后台扫描到事务执行失败的记录后，根据需求，分为2种处理方式
   1. 会一直重新执行，直到成功（若重试次数超过N次，触发告警，人工修复）
   2. 失败后，就对之前执行的事务执行回滚

### 3.5. 可靠消息队列方案——基于支持事务消息的“MQ中间件”

[Rocketmq执行过程（类似2阶段提交）](https://blog.csdn.net/weixin_34452850/article/details/88851419?utm_source=app&app_version=4.14.0)

1. Producer向Broker端发送Half Message
2. Broker ACK，Half Message发送成功
3. Producer执行本地事务。本地事务完毕，根据事务的状态，Producer向Broker发送二次确认消息，确认该Half Message的Commit或者Rollback状态。
4. Broker收到二次确认消息后
   1. 对于Commit状态，则直接发送到Consumer端执行消费逻辑
   2. 对于Rollback，则直接标记为失败，一段时间后清除，并不会发给Consumer
5. 正常情况下，到此分布式事务已经完成

剩下要处理的就是超时问题，即一段时间后Broker仍没有收到Producer的二次确认消息

1. 针对超时状态，Broker主动向Producer发起消息回查
2. Producer处理回查消息，返回对应的本地事务的执行结果
3. Broker针对回查消息的结果，执行Commit或Rollback操作，同Step4

**broker定时回查事务状态**

1. 场景: 发送commit/rollback到broker中的<u>半消息op队列</u>可能会丢失
2. 解决方案: broker定时去查询本地事务的执行结果，查询到commit/rollback后，执行消息的提交/丢弃



### 3.6. 最大努力通知

最大努力通知方案是最简单的一种柔性事务，适用于一些最终一致性时间敏感度第的业务，且被动方处理结果不影响主动方的处理结果。典型的使用案例：银行通知、商户通知

1. 不可靠消息
   - 业务活动主动方，在完成业务处理之后，向业务活动的被动方发送消息，直到通知N次后不再通知，允许消息丢失(不可靠消息)。
2. 定期校对：反查机制
   - 业务活动的被动方，根据定时策略，向业务活动主动方查询(主动方提供查询接口)，恢复丢失的业务消息。

### 3.7. 弱一致性方案


1. 重试（+回滚）+告警+人工修复
   - 对业务场景的要求比较多，对于那些业务流程复杂，需要维护的状态也很复杂，也就是很难根据状态进行自动补偿的时候，我们可以进一步简化操作：不做自动的状态补偿
   - 比如先扣库存，然后创建订单，如果订单创建失败则重试，重试还是失败则回滚，回滚失败则触发告警，然后人工根据日志记录进行修复。
   - 这个方案其实并没有什么特别的要求，甚至也说不上是什么方案，就是根据业务流程特性一步一步的操作，但里面的关键则是详细的操作日志记录和告警，至于是否需要尝试回滚也是可有可无的
   - 说白了这个方案就是放弃一致性的要求，也是成本最低最被动的方案
2. 事后处理-对账


---


总结：各方案的特点如下

- XA协议：基于XA协议的强一致事务使用起来相对简单，但是无法很好地应对互联网的短事务和高并发场景
- 2PC/3PC：依赖于数据库，能够很好的提供强一致性和强事务性，但相对来说延迟比较高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况，不适合高并发和高性能要求的场景。
- 本地事务状态表：方案轻量，容易实现，但与具体的业务场景耦合较高，不可公用。
- 可靠消息队列：适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦。典型的使用场景：注册送积分，登录送优惠券等。
- 最大努力通知：是分布式事务中要求最低的一种,适用于一些最终一致性时间敏感度低的业务；允许发起通知方处理业务失败，在接收通知方收到通知后积极进行失败处理，无论发起通知方如何处理结果都会不影响到接收通知方的后续处理；发起通知方需提供查询执行情况接口，用于接收通知方校对结果。典型的使用场景：银行通知、支付结果通知等。
- TCC：适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。但是对于业务的侵入性非常强，业务逻辑的每个分支都需要实现try、confirm、cancel三个操作。此外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。
- 弱一致性方案：上面给出的几种弱一致性方案则是在高并发等场景下为了提高系统的性能和可用性而在一致性方面做的妥协，一般需要结合具体的业务特点、实现成本等各方因素对某一最终一致性方案做改造。
